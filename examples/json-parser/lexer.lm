import { List, Option, Result, Token, ParseError } from "./types.lm"
import { str } from "@std"

struct LexResult {
  token: Token,
  pos: int
}

struct DigitScan {
  text: string,
  pos: int,
  found: bool
}

// Main lexer entry point
pub fn lex(input: string) -> Result<List<Token>, ParseError> {
  let acc: List<Token> = List.Nil
  match lex_tokens(input, 0, acc) {
    Result.Ok(tokens) => { return Result.Ok(list_reverse_tokens(tokens)) },
    Result.Err(e) => { return Result.Err(e) }
  }
}

// Recursive tokenization (accumulates in reverse)
fn lex_tokens(input: string, pos: int, acc: List<Token>) -> Result<List<Token>, ParseError> {
  let next_pos = skip_whitespace(input, pos)
  let len = str.length(input)

  if (next_pos >= len) {
    return Result.Ok(List.Cons(Token.Eof, acc))
  }

  match str.char_at(input, next_pos) {
    Option.Some(c) => {
      if (str.eq(c, "{")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.LeftBrace, acc))
      }
      if (str.eq(c, "}")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.RightBrace, acc))
      }
      if (str.eq(c, "[")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.LeftBracket, acc))
      }
      if (str.eq(c, "]")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.RightBracket, acc))
      }
      if (str.eq(c, ":")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.Colon, acc))
      }
      if (str.eq(c, ",")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.Comma, acc))
      }
      if (str.eq(c, "\"")) {
        match lex_string(input, next_pos + 1, "") {
          Result.Ok(res) => { return lex_tokens(input, res.pos, List.Cons(res.token, acc)) },
          Result.Err(e) => { return Result.Err(e) }
        }
      }
      if (str.is_digit(c) || str.eq(c, "-")) {
        match lex_number(input, next_pos, "") {
          Result.Ok(res) => { return lex_tokens(input, res.pos, List.Cons(res.token, acc)) },
          Result.Err(e) => { return Result.Err(e) }
        }
      }
      if (match_literal(input, next_pos, "true") && is_delimiter(input, next_pos + 4)) {
        return lex_tokens(input, next_pos + 4, List.Cons(Token.TrueLit, acc))
      }
      if (match_literal(input, next_pos, "false") && is_delimiter(input, next_pos + 5)) {
        return lex_tokens(input, next_pos + 5, List.Cons(Token.FalseLit, acc))
      }
      if (match_literal(input, next_pos, "null") && is_delimiter(input, next_pos + 4)) {
        return lex_tokens(input, next_pos + 4, List.Cons(Token.NullLit, acc))
      }

      return Result.Err(ParseError.UnexpectedChar(c, next_pos))
    },
    Option.None => { return Result.Err(ParseError.UnexpectedEof) }
  }
}

// Helper: skip whitespace
fn skip_whitespace(input: string, pos: int) -> int {
  match str.char_at(input, pos) {
    Option.Some(c) => {
      if (str.is_whitespace(c)) {
        return skip_whitespace(input, pos + 1)
      }
      return pos
    },
    Option.None => { return pos }
  }
}

// Helper: match literal string at position
fn match_literal(input: string, pos: int, literal: string) -> bool {
  return match_literal_at(input, pos, literal, 0)
}

fn match_literal_at(input: string, pos: int, literal: string, idx: int) -> bool {
  match str.char_at(literal, idx) {
    Option.None => { return true },
    Option.Some(ch) => {
      match str.char_at(input, pos + idx) {
        Option.Some(c) => {
          if (str.eq(c, ch)) {
            return match_literal_at(input, pos, literal, idx + 1)
          }
          return false
        },
        Option.None => { return false }
      }
    }
  }
}

fn is_delimiter(input: string, pos: int) -> bool {
  match str.char_at(input, pos) {
    Option.None => { return true },
    Option.Some(c) => {
      if (str.is_whitespace(c)) { return true }
      if (str.eq(c, ",")) { return true }
      if (str.eq(c, "]")) { return true }
      if (str.eq(c, "}")) { return true }
      if (str.eq(c, ":")) { return true }
      return false
    }
  }
}

fn escape_char(c: string) -> Option<string> {
  if (str.eq(c, "\"")) { return Option.Some("\"") }
  if (str.eq(c, "\\")) { return Option.Some("\\") }
  if (str.eq(c, "/")) { return Option.Some("/") }
  if (str.eq(c, "b")) { return Option.Some("\u0008") }
  if (str.eq(c, "f")) { return Option.Some("\u000C") }
  if (str.eq(c, "n")) { return Option.Some("\u000A") }
  if (str.eq(c, "r")) { return Option.Some("\u000D") }
  if (str.eq(c, "t")) { return Option.Some("\u0009") }
  return Option.None
}

// Lex string literal (basic escapes)
fn lex_string(input: string, pos: int, acc: string) -> Result<LexResult, ParseError> {
  match str.char_at(input, pos) {
    Option.None => { return Result.Err(ParseError.UnexpectedEof) },
    Option.Some(c) => {
      if (str.eq(c, "\"")) {
        return Result.Ok(LexResult { token: Token.StringLit(acc), pos: pos + 1 })
      }
      if (str.eq(c, "\\")) {
        match str.char_at(input, pos + 1) {
          Option.None => { return Result.Err(ParseError.UnexpectedEof) },
          Option.Some(esc) => {
            match escape_char(esc) {
              Option.Some(decoded) => { return lex_string(input, pos + 2, str.concat(acc, decoded)) },
              Option.None => { return Result.Err(ParseError.InvalidString(acc)) }
            }
          }
        }
      }

      return lex_string(input, pos + 1, str.concat(acc, c))
    }
  }
}

fn take_digits(input: string, pos: int, acc: string, found: bool) -> DigitScan {
  match str.char_at(input, pos) {
    Option.Some(c) => {
      if (str.is_digit(c)) {
        return take_digits(input, pos + 1, str.concat(acc, c), true)
      }
      return DigitScan { text: acc, pos: pos, found: found }
    },
    Option.None => { return DigitScan { text: acc, pos: pos, found: found } }
  }
}

// Lex number literal
fn lex_number(input: string, pos: int, acc: string) -> Result<LexResult, ParseError> {
  let mut scan_pos = pos
  let mut text = acc

  match str.char_at(input, scan_pos) {
    Option.Some(c) => {
      if (str.eq(c, "-")) {
        text = str.concat(text, "-")
        scan_pos = scan_pos + 1
      }
    },
    Option.None => { return Result.Err(ParseError.UnexpectedEof) }
  }

  let mut scan = take_digits(input, scan_pos, text, false)
  if (scan.found == false) {
    return Result.Err(ParseError.InvalidNumber(scan.text))
  }

  scan_pos = scan.pos
  text = scan.text

  match str.char_at(input, scan_pos) {
    Option.Some(c) => {
      if (str.eq(c, ".")) {
        scan = take_digits(input, scan_pos + 1, str.concat(text, "."), false)
        if (scan.found == false) {
          return Result.Err(ParseError.InvalidNumber(scan.text))
        }
        scan_pos = scan.pos
        text = scan.text
      }
    },
    Option.None => {}
  }

  match str.char_at(input, scan_pos) {
    Option.Some(c) => {
      if (str.eq(c, "e") || str.eq(c, "E")) {
        text = str.concat(text, c)
        scan_pos = scan_pos + 1
        match str.char_at(input, scan_pos) {
          Option.Some(sign) => {
            if (str.eq(sign, "+") || str.eq(sign, "-")) {
              text = str.concat(text, sign)
              scan_pos = scan_pos + 1
            }
          },
          Option.None => {}
        }
        scan = take_digits(input, scan_pos, text, false)
        if (scan.found == false) {
          return Result.Err(ParseError.InvalidNumber(scan.text))
        }
        scan_pos = scan.pos
        text = scan.text
      }
    },
    Option.None => {}
  }

  match str.to_float(text) {
    Result.Ok(n) => { return Result.Ok(LexResult { token: Token.NumberLit(n), pos: scan_pos }) },
    Result.Err(_) => { return Result.Err(ParseError.InvalidNumber(text)) }
  }
}

fn list_nil_tokens() -> List<Token> {
  return List.Nil
}

fn list_reverse_tokens(list: List<Token>) -> List<Token> {
  return list_reverse_tokens_into(list, list_nil_tokens())
}

fn list_reverse_tokens_into(list: List<Token>, acc: List<Token>) -> List<Token> {
  match list {
    List.Nil => { return acc },
    List.Cons(head, tail) => { return list_reverse_tokens_into(tail, List.Cons(head, acc)) }
  }
}

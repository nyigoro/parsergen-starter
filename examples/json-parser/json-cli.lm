import { io, str } from "@std"

// Core data structures for JSON parsing

// Recursive list type
pub enum List<T> {
  Nil,
  Cons(T, List<T>)
}

// Standard option type
pub enum Option<T> {
  Some(T),
  None
}

// Standard result type
pub enum Result<T, E> {
  Ok(T),
  Err(E)
}

// Key-value pair for JSON objects
pub struct Entry {
  key: string,
  value: JsonValue
}

// JSON value representation
pub enum JsonValue {
  Null,
  Bool(bool),
  Number(float),
  String(string),
  Array(List<JsonValue>),
  Object(List<Entry>)
}

// Lexer tokens
pub enum Token {
  LeftBrace,
  RightBrace,
  LeftBracket,
  RightBracket,
  Colon,
  Comma,
  StringLit(string),
  NumberLit(float),
  TrueLit,
  FalseLit,
  NullLit,
  Eof
}

// Parse errors with context
pub enum ParseError {
  UnexpectedToken(string, int),
  UnexpectedEof,
  InvalidNumber(string),
  InvalidString(string),
  UnexpectedChar(string, int)
}


struct LexResult {
  token: Token,
  pos: int
}

struct DigitScan {
  text: string,
  pos: int,
  found: bool
}

// Main lexer entry point
pub fn lex(input: string) -> Result<List<Token>, ParseError> {
  let acc: List<Token> = List.Nil
  match lex_tokens(input, 0, acc) {
    Result.Ok(tokens) => { return Result.Ok(list_reverse_tokens(tokens)) },
    Result.Err(e) => { return Result.Err(e) }
  }
}

// Recursive tokenization (accumulates in reverse)
fn lex_tokens(input: string, pos: int, acc: List<Token>) -> Result<List<Token>, ParseError> {
  let next_pos = skip_whitespace(input, pos)
  let len = str.length(input)

  if (next_pos >= len) {
    return Result.Ok(List.Cons(Token.Eof, acc))
  }

  match str.char_at(input, next_pos) {
    Option.Some(c) => {
      if (str.eq(c, "{")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.LeftBrace, acc))
      }
      if (str.eq(c, "}")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.RightBrace, acc))
      }
      if (str.eq(c, "[")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.LeftBracket, acc))
      }
      if (str.eq(c, "]")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.RightBracket, acc))
      }
      if (str.eq(c, ":")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.Colon, acc))
      }
      if (str.eq(c, ",")) {
        return lex_tokens(input, next_pos + 1, List.Cons(Token.Comma, acc))
      }
      if (str.eq(c, "\"")) {
        match lex_string(input, next_pos + 1, "") {
          Result.Ok(res) => { return lex_tokens(input, res.pos, List.Cons(res.token, acc)) },
          Result.Err(e) => { return Result.Err(e) }
        }
      }
      if (str.is_digit(c) || str.eq(c, "-")) {
        match lex_number(input, next_pos, "") {
          Result.Ok(res) => { return lex_tokens(input, res.pos, List.Cons(res.token, acc)) },
          Result.Err(e) => { return Result.Err(e) }
        }
      }
      if (match_literal(input, next_pos, "true") && is_delimiter(input, next_pos + 4)) {
        return lex_tokens(input, next_pos + 4, List.Cons(Token.TrueLit, acc))
      }
      if (match_literal(input, next_pos, "false") && is_delimiter(input, next_pos + 5)) {
        return lex_tokens(input, next_pos + 5, List.Cons(Token.FalseLit, acc))
      }
      if (match_literal(input, next_pos, "null") && is_delimiter(input, next_pos + 4)) {
        return lex_tokens(input, next_pos + 4, List.Cons(Token.NullLit, acc))
      }

      return Result.Err(ParseError.UnexpectedChar(c, next_pos))
    },
    Option.None => { return Result.Err(ParseError.UnexpectedEof) }
  }
}

// Helper: skip whitespace
fn skip_whitespace(input: string, pos: int) -> int {
  match str.char_at(input, pos) {
    Option.Some(c) => {
      if (str.is_whitespace(c)) {
        return skip_whitespace(input, pos + 1)
      }
      return pos
    },
    Option.None => { return pos }
  }
}

// Helper: match literal string at position
fn match_literal(input: string, pos: int, literal: string) -> bool {
  return match_literal_at(input, pos, literal, 0)
}

fn match_literal_at(input: string, pos: int, literal: string, idx: int) -> bool {
  match str.char_at(literal, idx) {
    Option.None => { return true },
    Option.Some(ch) => {
      match str.char_at(input, pos + idx) {
        Option.Some(c) => {
          if (str.eq(c, ch)) {
            return match_literal_at(input, pos, literal, idx + 1)
          }
          return false
        },
        Option.None => { return false }
      }
    }
  }
}

fn is_delimiter(input: string, pos: int) -> bool {
  match str.char_at(input, pos) {
    Option.None => { return true },
    Option.Some(c) => {
      if (str.is_whitespace(c)) { return true }
      if (str.eq(c, ",")) { return true }
      if (str.eq(c, "]")) { return true }
      if (str.eq(c, "}")) { return true }
      if (str.eq(c, ":")) { return true }
      return false
    }
  }
}

fn escape_char(c: string) -> Option<string> {
  if (str.eq(c, "\"")) { return Option.Some("\"") }
  if (str.eq(c, "\\")) { return Option.Some("\\") }
  if (str.eq(c, "/")) { return Option.Some("/") }
  if (str.eq(c, "b")) { return Option.Some("\u0008") }
  if (str.eq(c, "f")) { return Option.Some("\u000C") }
  if (str.eq(c, "n")) { return Option.Some("\u000A") }
  if (str.eq(c, "r")) { return Option.Some("\u000D") }
  if (str.eq(c, "t")) { return Option.Some("\u0009") }
  return Option.None
}

// Lex string literal (basic escapes)
fn lex_string(input: string, pos: int, acc: string) -> Result<LexResult, ParseError> {
  match str.char_at(input, pos) {
    Option.None => { return Result.Err(ParseError.UnexpectedEof) },
    Option.Some(c) => {
      if (str.eq(c, "\"")) {
        return Result.Ok(LexResult { token: Token.StringLit(acc), pos: pos + 1 })
      }
      if (str.eq(c, "\\")) {
        match str.char_at(input, pos + 1) {
          Option.None => { return Result.Err(ParseError.UnexpectedEof) },
          Option.Some(esc) => {
            match escape_char(esc) {
              Option.Some(decoded) => { return lex_string(input, pos + 2, str.concat(acc, decoded)) },
              Option.None => { return Result.Err(ParseError.InvalidString(acc)) }
            }
          }
        }
      }

      return lex_string(input, pos + 1, str.concat(acc, c))
    }
  }
}

fn take_digits(input: string, pos: int, acc: string, found: bool) -> DigitScan {
  match str.char_at(input, pos) {
    Option.Some(c) => {
      if (str.is_digit(c)) {
        return take_digits(input, pos + 1, str.concat(acc, c), true)
      }
      return DigitScan { text: acc, pos: pos, found: found }
    },
    Option.None => { return DigitScan { text: acc, pos: pos, found: found } }
  }
}

// Lex number literal
fn lex_number(input: string, pos: int, acc: string) -> Result<LexResult, ParseError> {
  let mut scan_pos = pos
  let mut text = acc

  match str.char_at(input, scan_pos) {
    Option.Some(c) => {
      if (str.eq(c, "-")) {
        text = str.concat(text, "-")
        scan_pos = scan_pos + 1
      }
    },
    Option.None => { return Result.Err(ParseError.UnexpectedEof) }
  }

  let mut scan = take_digits(input, scan_pos, text, false)
  if (scan.found == false) {
    return Result.Err(ParseError.InvalidNumber(scan.text))
  }

  scan_pos = scan.pos
  text = scan.text

  match str.char_at(input, scan_pos) {
    Option.Some(c) => {
      if (str.eq(c, ".")) {
        scan = take_digits(input, scan_pos + 1, str.concat(text, "."), false)
        if (scan.found == false) {
          return Result.Err(ParseError.InvalidNumber(scan.text))
        }
        scan_pos = scan.pos
        text = scan.text
      }
    },
    Option.None => {}
  }

  match str.char_at(input, scan_pos) {
    Option.Some(c) => {
      if (str.eq(c, "e") || str.eq(c, "E")) {
        text = str.concat(text, c)
        scan_pos = scan_pos + 1
        match str.char_at(input, scan_pos) {
          Option.Some(sign) => {
            if (str.eq(sign, "+") || str.eq(sign, "-")) {
              text = str.concat(text, sign)
              scan_pos = scan_pos + 1
            }
          },
          Option.None => {}
        }
        scan = take_digits(input, scan_pos, text, false)
        if (scan.found == false) {
          return Result.Err(ParseError.InvalidNumber(scan.text))
        }
        scan_pos = scan.pos
        text = scan.text
      }
    },
    Option.None => {}
  }

  match str.to_float(text) {
    Result.Ok(n) => { return Result.Ok(LexResult { token: Token.NumberLit(n), pos: scan_pos }) },
    Result.Err(_) => { return Result.Err(ParseError.InvalidNumber(text)) }
  }
}

fn list_nil_tokens() -> List<Token> {
  return List.Nil
}

fn list_reverse_tokens(list: List<Token>) -> List<Token> {
  return list_reverse_tokens_into(list, list_nil_tokens())
}

fn list_reverse_tokens_into(list: List<Token>, acc: List<Token>) -> List<Token> {
  match list {
    List.Nil => { return acc },
    List.Cons(head, tail) => { return list_reverse_tokens_into(tail, List.Cons(head, acc)) }
  }
}


struct ParseResult {
  value: JsonValue,
  rest: List<Token>
}

struct MembersResult {
  members: List<Entry>,
  rest: List<Token>
}

struct ElementsResult {
  elements: List<JsonValue>,
  rest: List<Token>
}

// Main parse entry point
pub fn parse(input: string) -> Result<JsonValue, ParseError> {
  match lex(input) {
    Result.Ok(tokens) => {
      match parse_value(tokens) {
        Result.Ok(res) => {
          match res.rest {
            List.Cons(tok, _) => {
              if (token_eq(tok, Token.Eof)) {
                return Result.Ok(res.value)
              }
              return Result.Err(ParseError.UnexpectedToken(token_name(tok), 0))
            },
            List.Nil => { return Result.Ok(res.value) }
          }
        },
        Result.Err(e) => { return Result.Err(e) }
      }
    },
    Result.Err(e) => { return Result.Err(e) }
  }
}

// Parse any JSON value
fn parse_value(tokens: List<Token>) -> Result<ParseResult, ParseError> {
  match tokens {
    List.Nil => { return Result.Err(ParseError.UnexpectedEof) },
    List.Cons(tok, rest) => {
      match tok {
        Token.NullLit => { return Result.Ok(ParseResult { value: JsonValue.Null, rest: rest }) },
        Token.TrueLit => { return Result.Ok(ParseResult { value: JsonValue.Bool(true), rest: rest }) },
        Token.FalseLit => { return Result.Ok(ParseResult { value: JsonValue.Bool(false), rest: rest }) },
        Token.NumberLit(n) => { return Result.Ok(ParseResult { value: JsonValue.Number(n), rest: rest }) },
        Token.StringLit(s) => { return Result.Ok(ParseResult { value: JsonValue.String(s), rest: rest }) },
        Token.LeftBrace => { return parse_object(rest) },
        Token.LeftBracket => { return parse_array(rest) },
        _ => { return Result.Err(ParseError.UnexpectedToken(token_name(tok), 0)) }
      }
    }
  }
}

// Parse object: { "key": value, ... }
fn parse_object(tokens: List<Token>) -> Result<ParseResult, ParseError> {
  match tokens {
    List.Nil => { return Result.Err(ParseError.UnexpectedEof) },
    List.Cons(tok, _) => {
      if (token_eq(tok, Token.RightBrace)) {
        return Result.Ok(ParseResult { value: JsonValue.Object(List.Nil), rest: tokens })
      }
      match parse_members(tokens, List.Nil) {
        Result.Ok(members_res) => {
          match expect_token(members_res.rest, Token.RightBrace) {
            Result.Ok(rest) => {
              return Result.Ok(ParseResult {
                value: JsonValue.Object(list_reverse_entries(members_res.members)),
                rest: rest
              })
            },
            Result.Err(e) => { return Result.Err(e) }
          }
        },
        Result.Err(e) => { return Result.Err(e) }
      }
    }
  }
}

// Parse object members
fn parse_members(tokens: List<Token>, acc: List<Entry>) -> Result<MembersResult, ParseError> {
  match tokens {
    List.Cons(tok, rest1) => {
      match tok {
        Token.StringLit(key) => {
          match expect_token(rest1, Token.Colon) {
            Result.Ok(rest2) => {
              match parse_value(rest2) {
                Result.Ok(val_res) => {
                  let entry = Entry { key: key, value: val_res.value }
                  match val_res.rest {
                    List.Cons(next, rest3) => {
                      if (token_eq(next, Token.Comma)) {
                        return parse_members(rest3, List.Cons(entry, acc))
                      }
                      return Result.Ok(MembersResult { members: List.Cons(entry, acc), rest: val_res.rest })
                    },
                    List.Nil => {
                      return Result.Ok(MembersResult { members: List.Cons(entry, acc), rest: val_res.rest })
                    }
                  }
                },
                Result.Err(e) => { return Result.Err(e) }
              }
            },
            Result.Err(e) => { return Result.Err(e) }
          }
        },
        _ => { return Result.Err(ParseError.UnexpectedToken(token_name(tok), 0)) }
      }
    },
    List.Nil => { return Result.Err(ParseError.UnexpectedEof) }
  }
}

// Parse array: [ value, ... ]
fn parse_array(tokens: List<Token>) -> Result<ParseResult, ParseError> {
  match tokens {
    List.Nil => { return Result.Err(ParseError.UnexpectedEof) },
    List.Cons(tok, _) => {
      if (token_eq(tok, Token.RightBracket)) {
        return Result.Ok(ParseResult { value: JsonValue.Array(List.Nil), rest: tokens })
      }
      match parse_elements(tokens, List.Nil) {
        Result.Ok(elems_res) => {
          match expect_token(elems_res.rest, Token.RightBracket) {
            Result.Ok(rest) => {
              return Result.Ok(ParseResult {
                value: JsonValue.Array(list_reverse_values(elems_res.elements)),
                rest: rest
              })
            },
            Result.Err(e) => { return Result.Err(e) }
          }
        },
        Result.Err(e) => { return Result.Err(e) }
      }
    }
  }
}

// Parse array elements
fn parse_elements(tokens: List<Token>, acc: List<JsonValue>) -> Result<ElementsResult, ParseError> {
  match parse_value(tokens) {
    Result.Ok(val_res) => {
      match val_res.rest {
        List.Cons(tok, rest) => {
          if (token_eq(tok, Token.Comma)) {
            return parse_elements(rest, List.Cons(val_res.value, acc))
          }
          return Result.Ok(ElementsResult { elements: List.Cons(val_res.value, acc), rest: val_res.rest })
        },
        List.Nil => { return Result.Ok(ElementsResult { elements: List.Cons(val_res.value, acc), rest: val_res.rest }) }
      }
    },
    Result.Err(e) => { return Result.Err(e) }
  }
}

// Expect a specific token
fn expect_token(tokens: List<Token>, expected: Token) -> Result<List<Token>, ParseError> {
  match tokens {
    List.Nil => { return Result.Err(ParseError.UnexpectedEof) },
    List.Cons(tok, rest) => {
      if (token_eq(tok, expected)) {
        return Result.Ok(rest)
      }
      return Result.Err(ParseError.UnexpectedToken(token_name(tok), 0))
    }
  }
}

// Token equality check
fn token_eq(a: Token, b: Token) -> bool {
  match a {
    Token.LeftBrace => {
      match b {
        Token.LeftBrace => { return true },
        _ => { return false }
      }
    },
    Token.RightBrace => {
      match b {
        Token.RightBrace => { return true },
        _ => { return false }
      }
    },
    Token.LeftBracket => {
      match b {
        Token.LeftBracket => { return true },
        _ => { return false }
      }
    },
    Token.RightBracket => {
      match b {
        Token.RightBracket => { return true },
        _ => { return false }
      }
    },
    Token.Colon => {
      match b {
        Token.Colon => { return true },
        _ => { return false }
      }
    },
    Token.Comma => {
      match b {
        Token.Comma => { return true },
        _ => { return false }
      }
    },
    Token.Eof => {
      match b {
        Token.Eof => { return true },
        _ => { return false }
      }
    },
    _ => { return false }
  }
}

// Get token name for error messages
fn token_name(tok: Token) -> string {
  match tok {
    Token.LeftBrace => { return "{" },
    Token.RightBrace => { return "}" },
    Token.LeftBracket => { return "[" },
    Token.RightBracket => { return "]" },
    Token.Colon => { return ":" },
    Token.Comma => { return "," },
    Token.StringLit(_) => { return "string" },
    Token.NumberLit(_) => { return "number" },
    Token.TrueLit => { return "true" },
    Token.FalseLit => { return "false" },
    Token.NullLit => { return "null" },
    Token.Eof => { return "EOF" }
  }
}

// List reverse helper
fn list_nil_entries() -> List<Entry> {
  return List.Nil
}

fn list_reverse_entries(list: List<Entry>) -> List<Entry> {
  return list_reverse_entries_into(list, list_nil_entries())
}

fn list_reverse_entries_into(list: List<Entry>, acc: List<Entry>) -> List<Entry> {
  match list {
    List.Nil => { return acc },
    List.Cons(head, tail) => { return list_reverse_entries_into(tail, List.Cons(head, acc)) }
  }
}

fn list_nil_values() -> List<JsonValue> {
  return List.Nil
}

fn list_reverse_values(list: List<JsonValue>) -> List<JsonValue> {
  return list_reverse_values_into(list, list_nil_values())
}

fn list_reverse_values_into(list: List<JsonValue>, acc: List<JsonValue>) -> List<JsonValue> {
  match list {
    List.Nil => { return acc },
    List.Cons(head, tail) => { return list_reverse_values_into(tail, List.Cons(head, acc)) }
  }
}


// Main stringify entry point (pretty-printed with 2-space indent)
pub fn stringify(value: JsonValue) -> string {
  return stringify_indent(value, 0)
}

// Stringify with indentation level
fn stringify_indent(value: JsonValue, indent: int) -> string {
  match value {
    JsonValue.Null => { return "null" },
    JsonValue.Bool(b) => {
      if (b) { return "true" }
      return "false"
    },
    JsonValue.Number(n) => { return str.from_float(n) },
    JsonValue.String(s) => { return str.concat(str.concat("\"", escape_string(s)), "\"") },
    JsonValue.Array(elems) => { return stringify_array(elems, indent) },
    JsonValue.Object(members) => { return stringify_object(members, indent) }
  }
}

// Stringify array with indentation
fn stringify_array(elems: List<JsonValue>, indent: int) -> string {
  match elems {
    List.Nil => { return "[]" },
    _ => {
      let inner = stringify_elements(elems, indent + 1, true)
      return str.concat(str.concat("[\u000A", inner), str.concat("\u000A", str.concat(make_indent(indent), "]")))
    }
  }
}

// Stringify array elements
fn stringify_elements(elems: List<JsonValue>, indent: int, first: bool) -> string {
  match elems {
    List.Nil => { return "" },
    List.Cons(head, tail) => {
      let prefix = prefix_for(first)
      let elem_str = str.concat(make_indent(indent), stringify_indent(head, indent))
      match tail {
        List.Nil => { return str.concat(prefix, elem_str) },
        _ => { return str.concat(str.concat(prefix, elem_str), stringify_elements(tail, indent, false)) }
      }
    }
  }
}

// Stringify object with indentation
fn stringify_object(members: List<Entry>, indent: int) -> string {
  match members {
    List.Nil => { return "{}" },
    _ => {
      let inner = stringify_members(members, indent + 1, true)
      return str.concat(str.concat("{\u000A", inner), str.concat("\u000A", str.concat(make_indent(indent), "}")))
    }
  }
}

// Stringify object members
fn stringify_members(members: List<Entry>, indent: int, first: bool) -> string {
  match members {
    List.Nil => { return "" },
    List.Cons(head, tail) => {
      let prefix = prefix_for(first)
      let key_str = str.concat(str.concat("\"", escape_string(head.key)), "\"")
      let val_str = stringify_indent(head.value, indent)
      let member_str = str.concat(make_indent(indent), str.concat(key_str, str.concat(": ", val_str)))
      match tail {
        List.Nil => { return str.concat(prefix, member_str) },
        _ => { return str.concat(str.concat(prefix, member_str), stringify_members(tail, indent, false)) }
      }
    }
  }
}

fn prefix_for(first: bool) -> string {
  if (first) { return "" }
  return ",\u000A"
}

// Create indentation string (2 spaces per level)
fn make_indent(level: int) -> string {
  if (level <= 0) { return "" }
  return str.concat("  ", make_indent(level - 1))
}

// Escape string for JSON
fn escape_string(s: string) -> string {
  return escape_string_at(s, 0, "")
}

fn escape_string_at(s: string, pos: int, acc: string) -> string {
  match str.char_at(s, pos) {
    Option.None => { return acc },
    Option.Some(c) => {
      let escaped = escape_json_char(c)
      return escape_string_at(s, pos + 1, str.concat(acc, escaped))
    }
  }
}

fn escape_json_char(c: string) -> string {
  if (str.eq(c, "\"")) { return "\\\"" }
  if (str.eq(c, "\\")) { return "\\\\" }
  if (str.eq(c, "\u000A")) { return "\\n" }
  if (str.eq(c, "\u000D")) { return "\\r" }
  if (str.eq(c, "\u0009")) { return "\\t" }
  return c
}



pub fn main() -> void {
  // Read all input from stdin
  let input = read_all_input("")

  if (str.eq(input, "")) {
    io.eprintln("Error: No input provided")
  } else {
    process_json(input)
  }
}

fn read_all_input(acc: string) -> string {
  match io.readLine() {
    Option.Some(line) => { return read_all_input(str.concat(str.concat(acc, line), "\n")) },
    Option.None => { return acc }
  }
}

fn process_json(input: string) -> void {
  match parse(input) {
    Result.Ok(value) => {
      io.println(stringify(value))
    },
    Result.Err(error) => {
      io.eprintln("Parse error:")
      io.eprintln(format_error(error))
    }
  }
}

fn format_error(error: ParseError) -> string {
  match error {
    ParseError.UnexpectedToken(tok, pos) => {
      return str.concat("Unexpected token: ", str.concat(tok, str.concat(" at position ", str.from_int(pos))))
    },
    ParseError.UnexpectedEof => { return "Unexpected end of input" },
    ParseError.InvalidNumber(s) => { return str.concat("Invalid number: ", s) },
    ParseError.InvalidString(s) => { return str.concat("Invalid string: ", s) },
    ParseError.UnexpectedChar(c, pos) => {
      return str.concat("Unexpected character: ", str.concat(c, str.concat(" at position ", str.from_int(pos))))
    }
  }
}

main()
